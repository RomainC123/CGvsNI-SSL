5th model:
  Running vanilla supervised vs unsupervised (so max weight still at 30, during only supervised training the unsupervised loss term still exists)
  73.7% => 76.1%
  Small upgrade
  Model is mostly learning from the supervised part, unsupervised loss not doing enough
Same remark for 7th model


Testing:
  Training on a few epochs only with supervised loss and only on supervised part of the dataset (basicaly model init)
  Then normal training based of of this log
  Overfitting the supervised data ?

  Case where max weight = 0 vs normal train

20 epochs each
Maybe need to average the only supervised runs on a bunch of runs to reduce variance
Only supervised: 68.4%
Only supervised no unsup loss: 69.1%
Full dataset: 79.6%
