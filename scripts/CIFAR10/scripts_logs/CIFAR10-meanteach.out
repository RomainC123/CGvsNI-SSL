Initialising new SSH agent...
succeeded
Initialising new SSH agent...
succeeded
Building ZCA transform...

Starting training...
Data: CIFAR10
Number of samples: 60000
Number of classes: 10
Number of training samples: 50000
Number of labeled samples: 1000
Percent of labeled samples: 2.00%
Number of testing samples: 10000
Percent of testing samples: 16.67%
------------------------------------
Model: SimpleNet
SimpleNet(
  (gn): GaussianNoise()
  (activation): LeakyReLU(negative_slope=0.1)
  (conv1a): WN_Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1b): WN_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1c): WN_Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop1): Dropout(p=0.5, inplace=False)
  (conv2a): WN_Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2b): WN_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2c): WN_Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop2): Dropout(p=0.5, inplace=False)
  (conv3a): WN_Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))
  (conv3b): WN_Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv3c): WN_Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
  (ap3): AvgPool2d(kernel_size=6, stride=2, padding=0)
  (fc1): WN_Linear(in_features=128, out_features=10, bias=True)
)
Init mode: Normal
Number of parameters: 3121812
------------------------------------
Optimizer: Adam
Max learning rate: 0.0002
Betas: (0.9, 0.999)
Learning rate schedule:
Ramp up epochs: 80
Ramp up mult: 5
Ramp down epochs: 50
Ramp down mult: 12.5
Lower bound: 0.0
Upper bound: 1.0
Beta 1 schedule:
Ramp down epochs: 50
Ramp down mult: 12.5
Lower bound: 0.55
Upper bound: 1.0
------------------------------------
Method: Mean Teacher
Alpha teacher: 0.6
Unsupervised loss max weight: 0.6
Ramp up epochs: 80
Ramp up mult: 5
Lower bound: 0.0
Upper bound: 1.0
------------------------------------
Batch size: 100
Number of batches: 500
Starting epoch: 0
Total number of epochs: 300
Training time: 7:16:48
Training done

Testing...
              precision  recall  f1-score  support
0                 0.401   0.683     0.506     1000
1                 0.677   0.605     0.639     1000
2                 0.371   0.433     0.400     1000
3                 0.290   0.228     0.255     1000
4                 0.553   0.293     0.383     1000
5                 0.357   0.546     0.432     1000
6                 0.787   0.289     0.423     1000
7                 0.500   0.594     0.543     1000
8                 0.485   0.644     0.553     1000
9                 0.688   0.351     0.465     1000
macro avg         0.511   0.467     0.460    10000
weighted avg      0.511   0.467     0.460    10000
accuracy          0.467
Testing done
