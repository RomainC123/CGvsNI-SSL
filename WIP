19-04, 11:20
Changement de la fonction de calcul de loss dans tempens.py
Normalisation de la loss supervisée en divisant celle-ci par le nombre de sample labelisées par batch
Loss non supervisée est normalisée en la divisant par le nombre d'elems, ie batch size * nb classes (puis ajout du weight, qui normalize aussi en fonction du nombre de samples labelisées)
Tests sur MINST 1000 labels, 300 epochs
=> 98.7%
Tests sur CIFAR10 1000 labels, 300 epochs
=> 50.1%
CIFAR10 toujours avec des comportements de loss étranges

MNIST 100 labels, 300 epochs
=> 96.1% (20-04-2021_13:18:19)
MNIST 100 labels, 300 epochs, only supervised
=> 86.4% (20-04-2021_11:42:02)
MNIST 100 labels, 300 epochs, only unsup ?
=>

CIFAR10 : toujours remontée incompréhensible de la loss supervisée après 10 epochs

Important: loss comparables seulement avec le même modèle!
  Même si normalisée de façon à ignorer le grand nombre de labels sur la sup, et la batch size et nb classes sur l'unsup

Chute de sup loss forte au début puis remontée
  LR : pas de changement de comportement entre 0.0005, 0.001 et 0.003 => Probablement pas ça le problème
Resnet18 => Utilisable pour les deux datasets (en mode RGB)
Comparer les courbes de Resnet18 sur les deux datasets
Si toujours le problème de la loss initiale, alors problème lié au modèle, pas au dataset

Resnet18 RGB MNIST 1000 labels 60000 samples lr 0.001
=> 98.1% (20-04-2021_17:26:55)
Resnet18 RGB CIFAR10 1000 labels 60000 samples lr 0.001
=> 40.2% (20-04-2021_17:29:29)
Toujours rien pour CIFAR10, même comportement de loss

Adaptation d'un répo pour visualiser des courbes de loss d'un truc qui est sensé marcher
=> Pour chaque epoch, il voit toutes les samples non labelisées au plus une fois, et ensuite il ajoute à ces samples non labeliusées un nombre fixe de samples labelisées, qui peuvent être réutilisées
PAR DEFAUT, LANCE SANS CA !!!

Problème semble provenir du dataset, pas de l'algo (fin ça marche pixel sur MNIST)
Mérite d'être testé sur le problème final

CIFAR10 old loss VGG
=> 49.5% (26-04-2021_10:58:21)
CIFAR10 old loss SimpleNet
=> 53.3% (21-04-2021_20:52:53)

CIFAR10 new loss VGG
=> 41% (21-04-2021_13:07:22)
    Massive supervised loss drop at the start, unsupervised loss is dominating here (very unstable valuation accuracy)
CIFAR10 new loss SimpleNet
=> 45% (21-04-2021_13:51:32)
    Much smoother behavior, but very slow convergence of loss

CIFAR10 old loss VGG xavier
=> 47.0% (26-04-2021_10:59:01)
    Bad perf but good loss behavior (no more sup loss increase at the start)
CIFAR10 old loss SimpleNet xavier
=> 50.5% (21-04-2021_21:30:12)
    Weird loss behavior at the start

Old loss vgg with xavier => NO MORE RANDOM BEHAVIOR AT THE START
Test de ça avec new loss

CIFAR10 new loss VGG xavier
=> 27% lel (27-04-2021_14:18:25)

Training with lr starting at 10% instead of 0%
CIFAR10 old loss VGG
=> 45.3% (03-05-2021_09:08:32)
Plus trop le comportement étrange en début d'entraînement
CIFAR10 new loss VGG
=> 44.1% (03-05-2021_09:09:00)
Pareil, pas d'anomalie au début

Lancer CIFAR10 full labels no unsup loss
=> 81.2 % (03-05-2021_11:48:53)
Cela fonctionne correctement, donc pas de problème sur la partie supervisée
