19-04, 11:20
Changement de la fonction de calcul de loss dans tempens.py
Normalisation de la loss supervisée en divisant celle-ci par le nombre de sample labelisées par batch
Loss non supervisée est normalisée en la divisant par le nombre d'elems, ie batch size * nb classes (puis ajout du weight, qui normalize aussi en fonction du nombre de samples labelisées)
Tests sur MINST 1000 labels, 300 epochs
=> 98.7%
Tests sur CIFAR10 1000 labels, 300 epochs
=> 50.1%
CIFAR10 toujours avec des comportements de loss étranges

MNIST 100 labels, 300 epochs
=> 96.1%
MNIST 100 labels, 300 epochs, only supervised
=> 86.4%
MNIST 100 labels, 300 epochs, only unsup ?
=>

CIFAR10 : toujours remontée incompréhensible de la loss supervisée après 10 epochs

Important: loss comparables seulement avec le même modèle!
  Même si normalisée de façon à ignorer le grand nombre de labels sur la sup, et la batch size et nb classes sur l'unsup

Chute de sup loss forte au début puis remontée
  LR : pas de changement de comportement entre 0.0005, 0.001 et 0.003 => Probablement pas ça le problème
Resnet18 => Utilisable pour les deux datasets (en mode RGB)
Comparer les courbes de Resnet18 sur les deux datasets
Si toujours le problème de la loss initiale, alors problème lié au modèle, pas au dataset

Resnet18 RGB MNIST 1000 labels 60000 samples lr 0.001
=> 98.1%
Resnet18 RGB CIFAR10 1000 labels 60000 samples lr 0.001
=> 40.2%
Toujours rien pour CIFAR10, même comportement de loss

Adaptation d'un répo pour visualiser des courbes de loss d'un truc qui est sensé marcher
Tracer courbes
Regarder dataloader

CNN RGB CIFAR10 1000 labels lr 0.001



DO CGvsNI
Problème semble provenir du dataset, pas de l'algo (fin ça marche pixel sur MNIST)
Mérite d'être testé sur le problème final

Run CIFAR10 same loss as repo
=> 
